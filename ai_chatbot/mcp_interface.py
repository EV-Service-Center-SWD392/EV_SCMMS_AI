"""
MCP Interface for EV SCMMS AI Chatbot
Handles Gemini function calling for conversational AI interactions.
"""
import os
import json
import asyncio
import subprocess
from datetime import datetime
from typing import Dict, List, Any, Optional
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment from shared config
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', 'shared', 'config.env'))

# Configure Gemini
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))

class ConversationManager:
    """Manages conversation history and context."""
    
    def __init__(self):
        self.conversations: Dict[str, List[Dict]] = {}
    
    def add_message(self, conversation_id: str, role: str, content: str, function_calls: List = None):
        """Add a message to conversation history."""
        if conversation_id not in self.conversations:
            self.conversations[conversation_id] = []
        
        message = {
            "timestamp": datetime.now().isoformat(),
            "role": role,
            "content": content,
            "function_calls": function_calls or []
        }
        
        self.conversations[conversation_id].append(message)
    
    def get_conversation(self, conversation_id: str) -> List[Dict]:
        """Get conversation history."""
        return self.conversations.get(conversation_id, [])
    
    def get_context_summary(self, conversation_id: str) -> str:
        """Get minimal context to reduce tokens."""
        history = self.get_conversation(conversation_id)
        if not history or len(history) == 0:
            return ""
        
        # Only get last user message for minimal context
        last_msg = history[-1]
        if last_msg["role"] == "user":
            return f"Last: {last_msg['content'][:50]}"
        
        return ""

class GeminiMCPChatbot:
    """Gemini-powered chatbot with MCP function calling for EV SCMMS."""
    
    def __init__(self):
        # Function declarations for MCP tools
        self.function_declarations = [
            genai.protos.FunctionDeclaration(
                name="get_spare_parts",
                description=(
                    "T√¨m ki·∫øm ph·ª• t√πng xe ƒëi·ªán theo t√™n, nh√† s·∫£n xu·∫•t, ho·∫∑c lo·∫°i ph·ª• t√πng. "
                    "T·ª± ƒë·ªông t√¨m ki·∫øm ƒëa tr∆∞·ªùng v·ªõi ƒë·ªô ch√≠nh x√°c cao. "
                    "K·∫øt qu·∫£ bao g·ªìm: t√™n, lo·∫°i ph·ª• t√πng, gi√° hi·ªán t·∫°i, s·ªë l∆∞·ª£ng t·ªìn kho, v√† c√°c th√¥ng tin li√™n quan kh√°c. "
                    "S·ª≠ d·ª•ng h√†m n√†y khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ th√¥ng tin, t√¨nh tr·∫°ng, ho·∫∑c gi√° c·ªßa ph·ª• t√πng."
                ),
                parameters=genai.protos.Schema(
                    type=genai.protos.Type.OBJECT,
                    properties={
                        "part_name": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="T·ª´ kh√≥a t√¨m ki·∫øm (t√™n, nh√† s·∫£n xu·∫•t, ho·∫∑c lo·∫°i ph·ª• t√πng)"
                        )
                    }
                )
            ),
            genai.protos.FunctionDeclaration(
                name="get_inventory",
                description=(
                    "Xem t√¨nh tr·∫°ng t·ªìn kho hi·ªán t·∫°i c·ªßa c√°c trung t√¢m b·∫£o d∆∞·ª°ng. "
                    "D√πng khi ng∆∞·ªùi d√πng mu·ªën bi·∫øt s·ªë l∆∞·ª£ng ph·ª• t√πng c√≥ s·∫µn."
                ),
                parameters=genai.protos.Schema(
                    type=genai.protos.Type.OBJECT,
                    properties={
                        "center_id": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="ID trung t√¢m c·ª• th·ªÉ (t√πy ch·ªçn)"
                        )
                    }
                )
            ),
            genai.protos.FunctionDeclaration(
                name="get_usage_history",
                description=(
                    "L·∫•y l·ªãch s·ª≠ s·ª≠ d·ª•ng ph·ª• t√πng ƒë·ªÉ ph√¢n t√≠ch xu h∆∞·ªõng v√† d·ª± b√°o nhu c·∫ßu. "
                    "C√≥ th·ªÉ l·ªçc theo t√™n ph·ª• t√πng, ID ph·ª• t√πng v√† trung t√¢m, trong kho·∫£ng 1-24 th√°ng."
                ),
                parameters=genai.protos.Schema(
                    type=genai.protos.Type.OBJECT,
                    properties={
                        "months": genai.protos.Schema(
                            type=genai.protos.Type.INTEGER,
                            description="S·ªë th√°ng l·ªãch s·ª≠ c·∫ßn xem (1-24)"
                        ),
                        "part_name": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="T√™n ph·ª• t√πng ƒë·ªÉ t√¨m ki·∫øm (t√πy ch·ªçn)"
                        ),
                        "spare_part_id": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="ID ph·ª• t√πng c·ª• th·ªÉ (t√πy ch·ªçn)"
                        ),
                        "center_id": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="ID trung t√¢m c·ª• th·ªÉ (t√πy ch·ªçn)"
                        )
                    }
                )
            ),
            genai.protos.FunctionDeclaration(
                name="forecast_demand",
                description=(
                    "D·ª± b√°o nhu c·∫ßu ph·ª• t√πng trong t∆∞∆°ng lai (1-12 th√°ng) b·∫±ng AI. "
                    "C√≥ th·ªÉ d·ª± b√°o cho t·ª´ng ph·ª• t√πng theo t√™n ho·∫∑c ID v√† t·ª´ng trung t√¢m."
                ),
                parameters=genai.protos.Schema(
                    type=genai.protos.Type.OBJECT,
                    properties={
                        "months": genai.protos.Schema(
                            type=genai.protos.Type.INTEGER,
                            description="S·ªë th√°ng c·∫ßn d·ª± b√°o (1-12)"
                        ),
                        "part_name": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="T√™n ph·ª• t√πng ƒë·ªÉ d·ª± b√°o (t√πy ch·ªçn)"
                        ),
                        "spare_part_id": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="ID ph·ª• t√πng c·ª• th·ªÉ (t√πy ch·ªçn)"
                        ),
                        "center_id": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="ID trung t√¢m c·ª• th·ªÉ (t√πy ch·ªçn)"
                        )
                    }
                )
            ),
            genai.protos.FunctionDeclaration(
                name="create_sparepart",
                description=(
                    "H·ªó tr·ª£ t·∫°o ph·ª• t√πng m·ªõi. Ph√¢n t√≠ch th√¥ng tin ng∆∞·ªùi d√πng cung c·∫•p v√† tr·∫£ v·ªÅ "
                    "danh s√°ch c√°c tr∆∞·ªùng c·∫ßn thi·∫øt ƒë·ªÉ t·∫°o ph·ª• t√πng. AI kh√¥ng t·ª± ƒë·ªông t·∫°o v√†o database."
                ),
                parameters=genai.protos.Schema(
                    type=genai.protos.Type.OBJECT,
                    properties={
                        "name": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="T√™n ph·ª• t√πng (t√πy ch·ªçn)"
                        ),
                        "unitPrice": genai.protos.Schema(
                            type=genai.protos.Type.NUMBER,
                            description="Gi√° ƒë∆°n v·ªã (t√πy ch·ªçn)"
                        ),
                        "manufacturer": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="Nh√† s·∫£n xu·∫•t (t√πy ch·ªçn)"
                        ),
                        "typeName": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="Lo·∫°i ph·ª• t√πng (t√πy ch·ªçn)"
                        ),
                        "vehicleModelId": genai.protos.Schema(
                            type=genai.protos.Type.INTEGER,
                            description="ID m·∫´u xe (t√πy ch·ªçn)"
                        ),
                        "centerName": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="T√™n trung t√¢m (t√πy ch·ªçn)"
                        ),
                        "description": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="M√¥ t·∫£ ph·ª• t√πng (t√πy ch·ªçn)"
                        ),
                        "partNumber": genai.protos.Schema(
                            type=genai.protos.Type.STRING,
                            description="M√£ ph·ª• t√πng (t√πy ch·ªçn)"
                        )
                    }
                )
            )
        ]
        
        # Gemini model with function calling
        self.model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            tools=[genai.protos.Tool(function_declarations=self.function_declarations)],
            tool_config=genai.protos.ToolConfig(
                function_calling_config=genai.protos.FunctionCallingConfig(
                    mode=genai.protos.FunctionCallingConfig.Mode.AUTO
                )
            ),
            system_instruction="AI tr·ª£ l√Ω ph·ª• t√πng xe ƒëi·ªán EV Service Center. Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ ph·ª• t√πng‚Üíg·ªçi get_spare_parts M·ªòT L·∫¶N, t·ªìn kho‚Üíget_inventory, l·ªãch s·ª≠‚Üíget_usage_history, d·ª± b√°o‚Üíforecast_demand. Ch·ªâ g·ªçi function 1 l·∫ßn cho m·ªói y√™u c·∫ßu. Khi d·ª± b√°o ph·ª• t√πng c·ª• th·ªÉ, h√£y ƒë·ªÅ c·∫≠p t√™n ph·ª• t√πng v√† k·∫øt qu·∫£ d·ª± b√°o chi ti·∫øt.",
            generation_config={
                "temperature": 0.3,
                "top_p": 0.8,
                "max_output_tokens": 512  # Reduce output tokens
            }
        )
        
        # Fallback model without function calling
        self.fallback_model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            system_instruction="AI tr·ª£ l√Ω th√¢n thi·ªán cho h·ªá th·ªëng qu·∫£n l√Ω ph·ª• t√πng xe ƒëi·ªán EV Service Center. Tr·∫£ l·ªùi c√°c c√¢u h·ªèi chung v·ªÅ xe ƒëi·ªán, b·∫£o d∆∞·ª°ng, v√† h·ªó tr·ª£ kh√°ch h√†ng.",
            generation_config={
                "temperature": 0.7,
                "top_p": 0.9,
                "max_output_tokens": 512
            }
        )
        
        # Conversation manager
        self.conversation_manager = ConversationManager()
        
        # MCP server process
        self.mcp_process = None
    
    def start_mcp_server(self):
        """Start the shared MCP server."""
        if self.mcp_process is None:
            print("üöÄ Starting shared MCP server...")
            shared_dir = os.path.join(os.path.dirname(__file__), '..', 'shared')
            self.mcp_process = subprocess.Popen(
                ["python", "true_mcp_server.py"],
                cwd=shared_dir,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            import time
            time.sleep(2)
            print("‚úÖ Shared MCP server started")
    
    def stop_mcp_server(self):
        """Stop the MCP server."""
        if self.mcp_process:
            self.mcp_process.terminate()
            self.mcp_process.wait()
            self.mcp_process = None
            print("üîí MCP server stopped")
    
    async def call_mcp_function(self, function_name: str, arguments: dict):
        """Call MCP server function."""
        # Import shared database functions
        import sys
        sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'shared'))
        from db_connection import fetch
        
        if function_name == "get_spare_parts":
            part_name = arguments.get("part_name")
            
            # Filter out None values and "None" strings
            if part_name in [None, "None", ""]:
                part_name = None
            
            sql = """
            SELECT s.sparepartid, s.name, s.unitprice, s.manufacture, s.status,
                   i.centerid, i.quantity, i.minimumstocklevel, 
                   t.name as type_name, v.name as vehicle_model_name
            FROM sparepart_tuht s
            LEFT JOIN inventory_tuht i ON s.inventoryid = i.inventoryid
            LEFT JOIN spareparttype_tuht t ON s.typeid = t.typeid
            LEFT JOIN vehiclemodel v ON s.vehiclemodelid = v.modelid
            WHERE s.isactive = true
            """
            params = []
            
            if part_name:
                # Multi-field search: name, manufacture, type
                sql += " AND (s.name ILIKE %s OR s.manufacture ILIKE %s OR t.name ILIKE %s)"
                search_term = f"%{part_name}%"
                params.extend([search_term, search_term, search_term])
                sql += " ORDER BY CASE WHEN s.name ILIKE %s THEN 1 WHEN s.manufacture ILIKE %s THEN 2 ELSE 3 END, s.name"
                params.extend([search_term, search_term])
            else:
                sql += " ORDER BY s.name"
            
            sql += " LIMIT 20"
            rows = await fetch(sql, *params) if params else await fetch(sql)
            # Return comprehensive data from real Supabase database
            result_data = []
            for row in rows[:15]:  # Show up to 15 items
                result_data.append({
                    "id": row.get("sparepartid", ""),
                    "name": row.get("name", ""),
                    "price": row.get("unitprice", 0),
                    "manufacture": row.get("manufacture", ""),
                    "qty": row.get("quantity", 0),
                    "min_stock": row.get("minimumstocklevel", 0),
                    "center_id": row.get("centerid", ""),
                    "status": row.get("status", ""),
                    "type": row.get("type_name", ""),
                    "vehicle_model": row.get("vehicle_model_name", "")
                })
            return {"data": result_data, "count": len(result_data), "source": "supabase_real_data"}
        
        elif function_name == "get_inventory":
            center_id = arguments.get("center_id")
            
            # Filter out None values
            if center_id in [None, "None", ""]:
                center_id = None
            
            sql = """
            SELECT i.inventoryid, i.centerid, i.quantity, i.minimumstocklevel, i.status,
                   s.sparepartid, s.name as spare_part_name, s.unitprice, s.manufacture
            FROM inventory_tuht i
            LEFT JOIN sparepart_tuht s ON i.inventoryid = s.inventoryid
            WHERE i.isactive = true
            """
            params = []
            
            if center_id:
                sql += " AND i.centerid = %s"
                params.append(center_id)
            
            sql += " LIMIT 10"
            rows = await fetch(sql, *params) if params else await fetch(sql)
            # Real inventory data from Supabase
            inventory_data = []
            for row in rows[:8]:
                inventory_data.append({
                    "inventory_id": row.get("inventoryid", ""),
                    "center_id": row.get("centerid", ""),
                    "spare_part_id": row.get("sparepartid", ""),
                    "part_name": row.get("spare_part_name", ""),
                    "quantity": row.get("quantity", 0),
                    "min_stock": row.get("minimumstocklevel", 0),
                    "price": row.get("unitprice", 0),
                    "manufacture": row.get("manufacture", ""),
                    "status": row.get("status", "")
                })
            return {"data": inventory_data, "count": len(inventory_data), "source": "supabase_real_data"}
        
        elif function_name == "get_usage_history":
            months = arguments.get("months", 6)
            part_name = arguments.get("part_name")
            spare_part_id = arguments.get("spare_part_id")
            center_id = arguments.get("center_id")
            
            # Filter out None values
            if part_name in [None, "None", ""]:
                part_name = None
            if spare_part_id in [None, "None", ""]:
                spare_part_id = None
            if center_id in [None, "None", ""]:
                center_id = None
            
            months = max(1, min(24, months))
            
            sql = """
            SELECT h.usageid, h.sparepartid, h.centerid, h.quantityused, h.useddate, h.status,
                   s.name as spare_part_name, s.unitprice, c.name as center_name
            FROM sparepartusagehistory_tuht h
            LEFT JOIN sparepart_tuht s ON h.sparepartid = s.sparepartid
            LEFT JOIN centertuantm c ON h.centerid = c.centerid
            WHERE h.useddate >= (now() - (%s::int * interval '1 month')) AND h.isactive = true
            """
            params = [months]
            
            if part_name:
                sql += " AND s.name ILIKE %s"
                params.append(f"%{part_name}%")
            if spare_part_id:
                sql += " AND h.sparepartid = %s"
                params.append(spare_part_id)
            if center_id:
                sql += " AND h.centerid = %s"
                params.append(center_id)
                
            sql += " ORDER BY h.useddate DESC LIMIT 15"
            rows = await fetch(sql, *params)
            # Real usage history from Supabase
            usage_data = []
            for row in rows[:10]:
                usage_data.append({
                    "usage_id": row.get("usageid", ""),
                    "date": str(row.get("useddate", "")),
                    "spare_part_id": row.get("sparepartid", ""),
                    "part_name": row.get("spare_part_name", ""),
                    "center_id": row.get("centerid", ""),
                    "center_name": row.get("center_name", ""),
                    "quantity_used": row.get("quantityused", 0),
                    "price": row.get("unitprice", 0),
                    "status": row.get("status", "")
                })
            return {"data": usage_data, "count": len(usage_data), "months": months, "source": "supabase_real_data"}
        
        elif function_name == "forecast_demand":
            months = arguments.get("months", 6)
            part_name = arguments.get("part_name")
            spare_part_id = arguments.get("spare_part_id")
            center_id = arguments.get("center_id")
            
            # Filter out None values
            if part_name in [None, "None", ""]:
                part_name = None
            if spare_part_id in [None, "None", ""]:
                spare_part_id = None
            if center_id in [None, "None", ""]:
                center_id = None
            
            # If part_name is provided, find spare_part_id first
            if part_name and not spare_part_id:
                find_sql = "SELECT sparepartid, name, unitprice, manufacture FROM sparepart_tuht WHERE name ILIKE %s AND isactive = true LIMIT 1"
                find_rows = await fetch(find_sql, f"%{part_name}%")
                if find_rows:
                    spare_part_id = find_rows[0].get("sparepartid")
                    part_info = find_rows[0]
                else:
                    return {
                        "error": "part_not_found",
                        "message": f"Kh√¥ng t√¨m th·∫•y ph·ª• t√πng '{part_name}' trong h·ªá th·ªëng",
                        "searched_part_name": part_name
                    }
            else:
                part_info = None
            
            # Only proceed if we have spare_part_id
            if not spare_part_id:
                return {
                    "error": "no_part_specified",
                    "message": "C·∫ßn ch·ªâ ƒë·ªãnh ph·ª• t√πng c·ª• th·ªÉ ƒë·ªÉ d·ª± b√°o"
                }
            
            try:
                # Use integrated forecast engine
                from ai_chatbot.forecast_engine import run_forecast_async
                
                forecast_result = await run_forecast_async(
                    spare_part_id=spare_part_id,
                    center_id=center_id, 
                    forecast_months=max(1, min(12, months))
                )
                
                # Get spare part info if not already retrieved
                if not part_info and spare_part_id:
                    part_sql = "SELECT name, unitprice, manufacture FROM sparepart_tuht WHERE sparepartid = %s"
                    part_rows = await fetch(part_sql, spare_part_id)
                    if part_rows:
                        part_info = part_rows[0]
                
                return {
                    "forecast_months": months,
                    "forecast_result": forecast_result,
                    "part_info": part_info,
                    "searched_part_name": part_name,
                    "data_source": "integrated_supabase_engine",
                    "message": f"D·ª± b√°o cho {months} th√°ng t·ªõi ƒë√£ ho√†n th√†nh"
                }
            except Exception as e:
                return {
                    "error": str(e),
                    "message": f"D·ª± b√°o cho {months} th√°ng t·ªõi - L·ªói h·ªá th·ªëng t√≠ch h·ª£p"
                }
        
        elif function_name == "create_sparepart":
            # Ph√¢n t√≠ch th√¥ng tin ƒë√£ c√≥ v√† c√≤n thi·∫øu
            provided_fields = {}
            missing_fields = []
            
            # C√°c tr∆∞·ªùng b·∫Øt bu·ªôc theo request body m·∫´u
            required_fields = {
                "name": "T√™n ph·ª• t√πng",
                "unitPrice": "Gi√° ƒë∆°n v·ªã", 
                "manufacturer": "Nh√† s·∫£n xu·∫•t",
                "typeName": "Lo·∫°i ph·ª• t√πng",
                "vehicleModelId": "ID m·∫´u xe",
                "centerName": "T√™n trung t√¢m",
                "description": "M√¥ t·∫£",
                "partNumber": "M√£ ph·ª• t√πng"
            }
            
            # Ki·ªÉm tra th√¥ng tin ƒë√£ cung c·∫•p
            for field, label in required_fields.items():
                value = arguments.get(field)
                if value and value not in [None, "None", ""]:
                    provided_fields[field] = {"label": label, "value": value}
                else:
                    missing_fields.append({"field": field, "label": label})
            
            return {
                "action": "create_sparepart_form",
                "provided_fields": provided_fields,
                "missing_fields": missing_fields,
                "message": "Th√¥ng tin t·∫°o ph·ª• t√πng m·ªõi",
                "note": "AI s·∫Ω kh√¥ng t·ª± ƒë·ªông t·∫°o v√†o database. Frontend c·∫ßn hi·ªÉn th·ªã form ƒë·ªÉ ng∆∞·ªùi d√πng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin."
            }
        
        else:
            return {"error": f"Unknown function: {function_name}"}
    
    async def process_chat_message(self, message: str, conversation_id: str, user_id: str = "anonymous", context: dict = None) -> dict:
        """Process a chat message with MCP function calling."""
        try:
            # Start MCP server if needed
            if self.mcp_process is None:
                self.start_mcp_server()
            
            # Get conversation context
            context_summary = self.conversation_manager.get_context_summary(conversation_id)
            
            # Minimal context to reduce tokens
            contextualized_message = f"{context_summary} {message}" if context_summary else message
            
            # Start chat session
            chat = self.model.start_chat()
            response = chat.send_message(contextualized_message)
            
            print(f"üîç Response candidates: {len(response.candidates)}")
            if response.candidates:
                print(f"üîç Content parts: {len(response.candidates[0].content.parts)}")
                for i, part in enumerate(response.candidates[0].content.parts):
                    print(f"üîç Part {i}: has_function_call={hasattr(part, 'function_call')}")
                    if hasattr(part, 'function_call'):
                        print(f"üîç Function call: {part.function_call}")
            
            # Handle function calls - LIMIT TO 1 CALL ONLY
            function_results = []
            max_calls = 1  # Only allow 1 function call
            call_count = 0
            
            while call_count < max_calls:
                # Check if response has function calls
                has_function_call = False
                
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'function_call') and part.function_call:
                        function_call = part.function_call
                        function_name = function_call.name
                        function_args = dict(function_call.args) if function_call.args else {}
                        call_count += 1
                        has_function_call = True
                        
                        print(f"üîß Function call: {function_name}({function_args})")
                        
                        # Call MCP function with error handling
                        try:
                            function_result = await self.call_mcp_function(function_name, function_args)
                            # Check if function returned error
                            if "error" in function_result:
                                print(f"‚ö†Ô∏è Function error: {function_result['error']}")
                                # Fallback to generative chat
                                fallback_response = self.fallback_model.generate_content(message)
                                return {
                                    "success": True,
                                    "response": fallback_response.text,
                                    "mode": "generative_fallback",
                                    "conversation_id": conversation_id,
                                    "timestamp": datetime.now().isoformat()
                                }
                            
                            function_results.append({
                                "function": function_name,
                                "args": function_args,
                                "result": function_result
                            })
                            
                            # Send result back to Gemini
                            response = chat.send_message(
                                genai.protos.Content(
                                    parts=[genai.protos.Part(
                                        function_response=genai.protos.FunctionResponse(
                                            name=function_name,
                                            response={"result": json.dumps(function_result, default=str)}
                                        )
                                    )]
                                )
                            )
                        except Exception as func_error:
                            print(f"‚ö†Ô∏è Function call failed: {func_error}")
                            # Fallback to generative chat
                            fallback_response = self.fallback_model.generate_content(message)
                            return {
                                "success": True,
                                "response": fallback_response.text,
                                "mode": "generative_fallback",
                                "conversation_id": conversation_id,
                                "timestamp": datetime.now().isoformat()
                            }
                        break
                
                if not has_function_call:
                    break
            
            # Get final response or fallback to generative chat
            try:
                ai_response = response.text if response.text else "ƒê√£ x·ª≠ l√Ω y√™u c·∫ßu th√†nh c√¥ng."
                
                # If no function was called and response is empty/generic, use fallback
                if not function_results and (not ai_response or len(ai_response.strip()) < 10):
                    fallback_response = self.fallback_model.generate_content(message)
                    ai_response = fallback_response.text
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Error getting response text: {e}")
                # Fallback to generative chat on error
                try:
                    fallback_response = self.fallback_model.generate_content(message)
                    ai_response = fallback_response.text
                except:
                    ai_response = "ƒê√£ x·ª≠ l√Ω y√™u c·∫ßu th√†nh c√¥ng."
            
            # Save to conversation history
            self.conversation_manager.add_message(
                conversation_id, "user", message
            )
            self.conversation_manager.add_message(
                conversation_id, "assistant", ai_response, 
                [f["function"] for f in function_results]
            )
            
            return {
                "success": True,
                "response": ai_response,
                "function_calls": [f["function"] for f in function_results],
                "function_results": function_results,
                "conversation_id": conversation_id,
                "user_id": user_id,
                "timestamp": datetime.now().isoformat(),
                "function_call_count": len(function_results)
            }
            
        except Exception as e:
            error_msg = f"L·ªói x·ª≠ l√Ω tin nh·∫Øn: {str(e)}"
            
            # Save error to conversation
            self.conversation_manager.add_message(
                conversation_id, "user", message
            )
            self.conversation_manager.add_message(
                conversation_id, "error", error_msg
            )
            
            return {
                "success": False,
                "error": error_msg,
                "conversation_id": conversation_id,
                "timestamp": datetime.now().isoformat()
            }
    
    def get_conversation_history(self, conversation_id: str) -> List[Dict]:
        """Get conversation history."""
        return self.conversation_manager.get_conversation(conversation_id)
    
    def close(self):
        """Clean up resources."""
        self.stop_mcp_server()